function tokenize(code)
  lex = new Lexer(code)
  return [lex.tokens, lex.comments]
exports.tokenize = tokenize

class Lexer
  method initialize(code, line_number)
    me.code = code
    me.line = line_number or 1
    me.indent = 0
    me.indents = []
    me.tokenize()

  method tokenize()
    me.tokens = []
    me.comments = []
    last_token_type = null
    index = 0

    while index < me.code.length
      chunk = me.code.slice(index)
      for tt in token_types
        regex = tt[0]
        type = tt[1]
        text = regex.exec(chunk)?[0]
        if text?
          me.type = type
          break
      unless text
        code = this.code.toString().trim()
        context_len = 16 when code.length >= 16 otherwise code.length
        me.error("invalid token '#{code.slice(index,index+context_len)}...' on line #{this.line}") unless text?
      val = parse_token[me.type](text)
      if last_token_type is 'NEWLINE' and type isnt 'COMMENT' #check for indent/dedent
        me.handleIndentation type, text
      if type is 'COMMENT'
        comment_token = {text:text, line:me.line, value:val, type:type}
        if last_token_type is 'NEWLINE' or last_token_type doesnt exist
          comment_token.post_fix = no
        else
          comment_token.post_fix = yes
        if val.match(/\n/)
          comment_token.multiline = yes
        else
          comment_token.multiline = no
        me.comments.push comment_token
      else
        unless type is 'NEWLINE' and me.tokens[me.tokens.length - 1]?.type is 'NEWLINE'
          me.tokens.push {text:text, line:me.line, value:val, type:type, soft: last_token_type is 'WHITESPACE'}
      index += text.length
      me.line += text.match(/\n/g)?.length or 0
      last_token_type = type
    #add a trailing newline in case the user didn't
    me.tokens.push {text:'\n',line:me.line, value:'', type:'NEWLINE'}
    me.handleIndentation 'NEWLINE', '' #clear up any remaining indents at the end of the file
    #remove the newline if it wasn't needed
    me.tokens.pop() if me.tokens[me.tokens.length-1].type is 'NEWLINE'
  method handleIndentation(type, text)
    indentation = text.length if type is 'WHITESPACE' otherwise 0
    if indentation > me.indent
      me.indents.push me.indent
      me.indent = indentation
      me.tokens.push {text:text, line:me.line, value:'', type:'INDENT'}
    else if indentation < me.indent
      while me.indents.length > 0 and indentation < me.indent
        me.indent = me.indents.pop()
        me.error('indentation is misaligned on line ' + me.line) if indentation > me.indent
        me.tokens.push {text:text, line:me.line, value:'', type:'DEDENT'}
      me.error('indentation is misaligned') if indentation isnt me.indent

  method error(message)
    throw message

exports.Lexer = Lexer

parse_token = {}
parse_token.NUMBER = (text) ->
  return Number(text)
parse_token.STRING = (text) ->
  return text
parse_token.IDENTIFIER = (text) ->
  return text
parse_token.NEWLINE = (text) ->
  return ''
parse_token.WHITESPACE = (text) ->
  return ' '
parse_token.COMMENT = (text) ->
  rv = text.trim()
  rv = rv.replace /^#*\s*|#*$/g, ""
  rv = rv.replace /\n[\f\r\t\v\u00A0\u2028\u2029 ]*#*[\f\r\t\v\u00A0\u2028\u2029 ]*/g, '\n * '
  return rv.replace(/(\/\*)|(\*\/)/g, '**')
parse_token.LITERAL = (text) ->
  return text.replace(/[\f\r\t\v\u00A0\u2028\u2029 ]/, '')
parse_token.REGEX = (text) ->
  return text

token_types = [[/^###([^#][\s\S]*?)(?:###[^\n\S]*|(?:###)?$)|^(?:[^\n\S]*#(?!##[^#]).*)+/, 'COMMENT'],
               [/^(\/(?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*\/)([imgy]{0,4})(?!\w)/,'REGEX'],
               [/^0x[a-f0-9]+/i, 'NUMBER'],
               [/^[0-9]+(\.[0-9]+)?(e[+-]?[0-9]+)?/i, 'NUMBER'],
               [/^'(?:[^'\\]|\\.)*'/, 'STRING'],
               [/^"(?:[^"\\]|\\.)*"/, 'STRING'],
               [/^[$A-Za-z_\x7f-\uffff][$\w\x7f-\uffff]*/, 'IDENTIFIER'],
               [/^\n([\f\r\t\v\u00A0\u2028\u2029 ]*\n)*\r*/, 'NEWLINE'],
               [/^[\f\r\t\v\u00A0\u2028\u2029 ]+/, 'WHITESPACE'],
               [/^[\<\>\!\=]\=/, 'LITERAL'],
               [/^[\+\-\*\/\^\=\.><\(\)\[\]\,\.\{\}\:\?]/, 'LITERAL']]
