function tokenize(code)
  lex = new Lexer(code)
  return [lex.tokens, lex.comments]
exports.tokenize = tokenize

token_types = {}

class Lexer
  method initialize(code, line_number)
    me.code = code
    me.line = line_number or 1
    me.indent = 0
    me.indents = []
    me.tokenize()
    
  method tokenize()
    me.tokens = []
    me.comments = []
    last_token_type = null
    index = 0    
    while index < me.code.length
      chunk = me.code.slice(index)
      for tt in token_types
        regex = tt[0]
        type = tt[1]
        e = regex.exec(chunk)
        text = e?[0]
        if text?
          me.type = type
          break
      me.error("invalid token '#{me.code.slice(index,index+15)}...'") unless text exists
      value = text
      if last_token_type is 'NEWLINE' #check for indent/dedent
        me.handleIndentation type, text
      new_token = {text:text, line:me.line, value:value, type:type}
      if type is 'COMMENT'
        me.comments.push new_token
      else if type isnt 'WHITESPACE'
        me.tokens.push new_token
      index += text.length
      l = /\n/.exec(text)
      me.line += l?[0].length or 0
      last_token_type = type
    me.handleIndentation 'NEWLINE', '' #clear up any remaining indents at the end of the file
    
  method handleIndentation(type, text)
    indentation = text.length when type is 'WHITESPACE' otherwise 0
    if indentation > me.indent
      me.indents.push me.indent
      me.indent = indentation
      new_token = {text:text, line:me.line, value:'', type:'INDENT'}
      me.tokens.push new_token
    else if indentation < me.indent
      while me.indents.length > 0 and indentation < me.indent
        me.indent = me.indents.pop()
        me.error('indentation is misaligned') when indentation > me.indent
        new_token = {text:text, line:me.line, value:'', type:'DEDENT'}
        me.tokens.push new_token
      me.error('indentation is misaligned') when indentation isnt me.indent
      
  method error(message)
    throw(message)

exports.Lexer = Lexer


token_types = [[/^###([^#][\s\S]*?)(?:###[^\n\S]*|(?:###)?$)|^(?:\s*#(?!##[^#]).*)+/, 'COMMENT'],
    [/^(\/(?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*\/)([imgy]{0,4})(?!\w)/,'REGEX'],
    [/^0x[a-f0-9]+/i, 'NUMBER'],
    [/^[0-9]+(\.[0-9]+)?(e[+-]?[0-9]+)?/i, 'NUMBER'],
    [/^'([^']*(\\'))*[^']*'/, 'STRING'],
    [/^"([^"]*(\\"))*[^"]*"/, 'STRING'],
    [/^[$A-Za-z_\x7f-\uffff][$\w\x7f-\uffff]*/, 'IDENTIFIER'],
    [/^(\r*\n\r*)+/, 'NEWLINE'],
    [/^[\f\r\t\v\u00A0\u2028\u2029 ]+/, 'WHITESPACE'],
    [/^[\+\-\*\/\^\=\.><\(\)\[\]\,\.\{\}\:\?]/, 'LITERAL']]
    

